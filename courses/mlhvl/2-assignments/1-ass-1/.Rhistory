knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
mnist <- dataset_mnist()
# Understand dimensions of the dataset
dim(mnist$train$x)
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# Check new dimensions
dim(x_train)
dim(x_test)
x_train <- x_train / 255
x_test <- x_test / 255
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
# Test if it worked
y_train %>% as_tibble %>% head(5)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, input_shape = c(784)) %>%
layer_dense(units = 10, activation = 'softmax')
# Check resulting model
summary(model)
# Compile the model with loss function, optimizer function and metrics
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
# Verbose is on to help with the debugging of the model
history <- model %>% fit(
x_train, y_train,
batch_size = 128,
epochs = 12,
verbose = 1,
validation_split = 0.2 #This is to set aside the 20% of the data to check for performance
)
plot(history)
score <- model %>% evaluate(
x_test, y_test,
verbose = 0
)
score_loss <- score$loss
score_accuracy <- score$acc
paste(c("Score accuracy: ",score_accuracy,"; score loss: ",score_loss))
model_2 <- keras_model_sequential()
model_2 %>%
layer_dense(units = 256, input_shape = c(784), activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
# Summary of model relu
summary(model_2)
plot(history_2)
# Compile model relu
model_2 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
# Train model relu
history_2 <- model_2 %>% fit(
x_train, y_train,
batch_size = 128,
epochs = 12,
verbose = 1,
validation_split = 0.2
)
score_2 <- model_2 %>% evaluate(
x_test, y_test,
verbose = 0
)
plot(history_2)
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# Reshape to desired dimension to account for colours
x_train <- array_reshape(x_train, c(nrow(x_train), 28, 28, 1))
x_test <- array_reshape(x_test, c(nrow(x_test), 28, 28, 1))
dim(x_train)
dim(x_test)
# Rescale results from 0 to 1
x_train <- x_train / 255
x_test <- x_test / 255
# Categorical variables
y_train <- to_categorical(y_train)
y_test <- to_categorical(y_test)
model_3 <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3),
activation = 'relu', input_shape = c(28,28,1)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dense(units = 10, activation = 'softmax')
summary(model_3)
# Compile model with backpropagation of error procedure
model_3 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
# Fit the model with only 6 epochs
history_3 <- model_3 %>% fit(
x_train, y_train,
batch_size = 128,
epochs = 6,
verbose = 1,
validation_split = 0.2
)
# Compile model with backpropagation of error procedure
model_3 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
# Fit the model with only 6 epochs
history_3 <- model_3 %>% fit(
x_train, y_train,
batch_size = 128,
epochs = 6,
verbose = 1,
validation_split = 0.2
)
plot(history_3)
score_3 <- model_3 %>% evaluate(
x_test, y_test,
verbose = 0
)
historyDeep %>%
as_tibble %>%
write_csv(path = "histories/history_deep.csv")
history_3 %>%
as_tibble %>%
write_csv(path = "histories/history_deep.csv")
history_3 %>%
as_tibble
ggplot(history_3, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1) +
scale_y_continuous(limits=c(0,1))
history_3_tibble <- history_3 %>%
as_tibble
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1) +
scale_y_continuous(limits=c(0,1))
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1)
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1) +
scale_y_continuous(limits=c(0.8,1))
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1) +
scale_y_continuous(limits=c(0,1))
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1)
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1, scales = "free")
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1, scales = "free")
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1, scales = "free") +
scale_x_continuous()
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1, scales = "free") +
scale_x_continuous(breaks = C(1,2,3,4,5,6))
ggplot(history_3_tibble, aes(epoch, value, colour = data)) +
geom_point() +
geom_smooth(se = F) +
facet_wrap(~metric, ncol = 1, scales = "free") +
scale_x_continuous(breaks = c(1,2,3,4,5,6))
score_3$loss
score_3$acc
score_3$loss
as_tibble(c(score_3$loss,
score_3$acc))
as_tibble(c(score_3$loss,
score_3$acc),
rows = 1)
score_3$acc
score_3 %>% as_tibble %>% kable
model_4 <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3),
activation = 'relu', input_shape = c(28,28,1)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax') %>%
summary(model_4)
model_4 <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3),
activation = 'relu', input_shape = c(28,28,1)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax') %>%
summary(model_4)
model_4 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
model_4 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
model_4 <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3),
activation = 'relu', input_shape = c(28,28,1)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 10, activation = 'softmax')
summary(model_4)
model_4 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_adadelta(),
metrics = c('accuracy')
)
history_4 <- model_4 %>% fit(
x_train, y_train,
batch_size = 128,
epochs = 6,
verbose = 1,
validation_split = 0.2
)
plot(history_4)
cifar10 <- dataset_cifar10()
set_config( config( ssl.verifypeer = 0L ) )
cifar10 <- dataset_cifar10()
httr::set_config(httr::config(ssl_verifypeer=0L))
cifar10 <- dataset_cifar10()
httr::set_config(httr::config(ssl_verifypeer=0L, ssl_verifyhost=0L, sslversion=3))
cifar10 <- dataset_cifar10()
install.packages(openssl)
install.packages("openssl")
cifar10 <- dataset_cifar10()
install.packages("libcurl")
install.packages("httr")
install.packages("httr")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar10 <- dataset_cifar10()
cifar10
cifar10 <- dataset_cifar10()
install.packages("curl")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar10 <- dataset_cifar10()
cifar10 <- dataset_cifar10()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar10 <- dataset_cifar10()
devtools::install_github("rstudio/reticulate")
install.packages("devtools")
devtools::install_github("rstudio/reticulate")
install.packages()
install.packages("reticulate")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar10 <- dataset_cifar10()
library(kerasR)
cifar10 <- dataset_cifar10()
install_tensorflow(gpu = T)
devtools::install_github("rstudio/keras")
install_tensorflow(gpu = T)
?dataset_cifar10
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar10 <- dataset_cifar10()
system("wget https://raw.githubusercontent.com/mlampros/DataSets/master/cifar_10.zip")
cifar_10
cifar_10 <- read.table(unz("cifar_10.zip", "cifar_10.csv"), nrows = 60000, header = T, quote = "\"", sep = ",")
cifar_10
cifar_10$V1
install.packages("keras")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(cowplot)
library(readtext)
library(tidyverse)
cifar_10 <- dataset_cifar10()
install.packages("openssl")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(knitr)
library(papeR)
library(xtable)
library(readtext)
library(tidyverse)
cifar_10 <- dataset_cifar10()
tensorflow::install_tensorflow()
library(devtools)
install_github('rstudio/reticulate',force=T)
library(reticulate)
library(tensorflow)
install_tensorflow(version= "1.1.0")
install_github("rstudio/keras",force=T)
library(keras)
keras::install_keras()
devtools::install_github("rstudio/keras")
install.packages("keras", type = "source")
install.packages("kerasR")
install_keras(tensorflow = "1.8.0")
keras::install_keras()
reticulate::use_condaenv("r-tensorflow")
reticulate::py_config()
keras::install_keras()
install_tensorflow(version = "1.12")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
tensorflow::install_tensorflow()
reticulate::py_discover_config()
reticulate::use_condaenv("r-tensorflow")
reticulate::py_config()
library(keras)
install_keras()
library(keras)
library(kerasR)
reticulate::use_python()
install_keras()
install.packages("reticulate")
library(kerasR)
reticulate::use_python()
reticulate::use_python(2,7)
reticulate::use_python("2.7")
kerasR::keras_init()
?use_python
reticulate::use_python(/usr/local/bin/python3.7)
reticulate::use_python("/usr/local/bin/python3.7")
erasR::keras_init()
kerasR::keras_init()
library(keras)
use_condaenv(condaenv = NULL, conda = "auto", required = FALSE)
library(knitr)
library(papeR)
library(readtext)
library(tidyverse)
cifar_10 <- dataset_cifar10()
install_tensorflow()
install_keras()
library(reticulate)
conda_create("r-reticulate")
conda_install("r-reticulate", "scipy")
use_condaenv("r-reticulate")
install_tensorflow()
conda install -c conda-forge tensorflow
conda_install("tensorflow")
install_keras()
conda_install("keras")
mnist <- dataset_mnist()
devtools::install_github("rstudio/tensorflow")
library(tensorflow)
install_tensorflow(method = "conda")
install_tensorflow()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = F)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
set.seed(1)
library(keras)
library(kerasR)
library(knitr)
library(papeR)
library(xtable)
library(readtext)
library(tidyverse)
mnist <- dataset_mnist()
install_tensorflow()
conda activate r-reticulate
conda activate
library(reticulate)
conda activate
library(reticulate)
library(tensorflow)
use_python("/Library/Frameworks/Python.framework/Versions/3.7/bin/python3")
pip install h5py pyyaml requests Pillow scipy
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
sess = tf$Session()
install_tensorflow(version = "1.0.0")
Sys.setenv(TENSORFLOW_PYTHON="/Library/Frameworks/Python.framework/Versions/3.7/bin/python3")
sess = tf$Session()
tflow <- import("tensorflow")
tensorflow::install_tensorflow()
View(cifar_10)
rm cifar_10
remove cifar_10
rm(cifar_10)
